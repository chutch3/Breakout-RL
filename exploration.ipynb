{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self, size=100000):\n",
    "        self.buffer = deque(maxlen=size)\n",
    "\n",
    "    def add(self, experience_tuple):\n",
    "        self.buffer.append(experience_tuple)\n",
    "\n",
    "    def sample(self, size=64):\n",
    "        sample = random.sample(self.buffer, size)\n",
    "        batch_state, batch_action, batch_next_state, batch_reward, batch_done = map(lambda x: np.stack(x, axis=0), zip(*sample))\n",
    "        batch_state = torch.from_numpy(batch_state).float().to(device)\n",
    "        batch_next_state = torch.from_numpy(batch_next_state).float().to(device)\n",
    "        batch_action = torch.from_numpy(batch_action).long().to(device)\n",
    "        batch_reward = torch.from_numpy(batch_reward).float().to(device)\n",
    "        batch_done = torch.from_numpy(batch_done * 1).float().to(device)\n",
    "        \n",
    "\n",
    "        return batch_state, batch_action, batch_next_state, batch_reward, batch_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cov_out_size(dim_shape, padding, dilation, kernal_size, stride):\n",
    "     return int((dim_shape+(2*padding)-dilation*(kernal_size-1)-1)/stride + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_space, action_space, learning_rate=.0005):\n",
    "        super(DQN, self).__init__()\n",
    "        self.seed = torch.manual_seed(0)\n",
    "        self.action_space = action_space\n",
    "        self.height = state_space[0]\n",
    "        self.width = state_space[1]\n",
    "\n",
    "        self.cov1_in_channels = state_space[2]\n",
    "        self.cov1_out_channels = 16\n",
    "        self.cov1_kernal_size = 3\n",
    "        self.cov1_stride = 1\n",
    "        self.cov1_dilation = 1\n",
    "        self.cov1_padding = 0\n",
    "        self.cov1_out_shape = (\n",
    "         compute_cov_out_size(self.height, \n",
    "                              self.cov1_padding, \n",
    "                              self.cov1_dilation, \n",
    "                              self.cov1_kernal_size,\n",
    "                              self.cov1_stride),\n",
    "        compute_cov_out_size(self.width, \n",
    "                              self.cov1_padding, \n",
    "                              self.cov1_dilation, \n",
    "                              self.cov1_kernal_size,\n",
    "                              self.cov1_stride))\n",
    "\n",
    "        self.pool_kernal_size = 3\n",
    "        self.pool_stride = 1\n",
    "        self.pool_dilation = 1\n",
    "        self.pool_padding = 0\n",
    "        self.pool_out_shape = (\n",
    "         compute_cov_out_size(self.cov1_out_shape[0], \n",
    "                              self.pool_padding, \n",
    "                              self.pool_dilation, \n",
    "                              self.pool_kernal_size,\n",
    "                              self.pool_stride),\n",
    "         compute_cov_out_size(self.cov1_out_shape[1], \n",
    "                              self.pool_padding, \n",
    "                              self.pool_dilation, \n",
    "                              self.pool_kernal_size,\n",
    "                              self.pool_stride))\n",
    "        \n",
    "        self.cov2_in_channels = self.cov1_out_channels\n",
    "        self.cov2_out_channels = 6 \n",
    "        self.cov2_kernal_size = 3\n",
    "        self.cov2_stride = 1\n",
    "        self.cov2_dilation = 1 \n",
    "        self.cov2_padding = 0\n",
    "        self.cov2_out_shape = (\n",
    "         compute_cov_out_size(self.pool_out_shape[0], \n",
    "                              self.cov2_padding, \n",
    "                              self.cov2_dilation, \n",
    "                              self.cov2_kernal_size,\n",
    "                              self.cov2_stride),\n",
    "         compute_cov_out_size(self.pool_out_shape[1], \n",
    "                              self.cov2_padding, \n",
    "                              self.cov2_dilation, \n",
    "                              self.cov2_kernal_size,\n",
    "                              self.cov2_stride))\n",
    "\n",
    "        self.pool2_out_shape = (\n",
    "          compute_cov_out_size(self.cov2_out_shape[0], \n",
    "                              self.pool_padding, \n",
    "                              self.pool_dilation, \n",
    "                              self.pool_kernal_size,\n",
    "                              self.pool_stride),\n",
    "         compute_cov_out_size(self.cov2_out_shape[1], \n",
    "                              self.pool_padding, \n",
    "                              self.pool_dilation, \n",
    "                              self.pool_kernal_size,\n",
    "                              self.pool_stride))\n",
    "\n",
    "        self.linear1_in_features = self.cov2_out_channels \\\n",
    "                                  *self.pool2_out_shape[0] \\\n",
    "                                  *self.pool2_out_shape[1]\n",
    "\n",
    "        \n",
    "        # in_channels = color channels => rgb = 3\n",
    "        # out_channels = channels produced by the convolution\n",
    "        # kernal_size = height and width of convolution window\n",
    "        self.conv1 = nn.Conv2d(in_channels=self.cov1_in_channels, \n",
    "                               out_channels=self.cov1_out_channels, \n",
    "                               kernel_size=self.cov1_kernal_size, \n",
    "                               padding=self.cov1_padding,\n",
    "                               stride=self.cov1_stride,\n",
    "                               dilation=self.cov1_dilation)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=self.pool_kernal_size,\n",
    "                                 padding=self.pool_padding,\n",
    "                                 stride=self.pool_stride,\n",
    "                                 dilation=self.pool_dilation)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=self.cov2_in_channels, \n",
    "                               out_channels=self.cov2_out_channels,\n",
    "                               kernel_size=self.cov2_kernal_size,\n",
    "                               padding=self.cov2_padding, \n",
    "                               stride=self.cov2_stride,\n",
    "                               dilation=self.cov2_dilation)\n",
    "\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.fc1 = nn.Linear(self.linear1_in_features, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, self.action_space)\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self.linear1_in_features)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        return self.fc4(x)\n",
    "\n",
    "    def optimize(self, expected, actual):\n",
    "        loss = F.mse_loss(expected, actual)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.action_space = env.action_space.n\n",
    "        self.state_space = env.observation_space.shape\n",
    "\n",
    "        self.memory = Memory()\n",
    "        self.model = self.create_model()\n",
    "        self.target = self.create_model()\n",
    "        self.gamma = .5\n",
    "\n",
    "        self.epsilon_decay = .995\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = .01\n",
    "        self.tau = 0.001\n",
    "\n",
    "    def create_model(self):\n",
    "        return DQN(self.state_space, self.action_space).to(device)\n",
    "\n",
    "    def is_ready(self, threshold):\n",
    "        return len(self.memory.buffer) > threshold\n",
    "\n",
    "    def get_max_action(self, state):\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.model(state)\n",
    "        self.model.train()\n",
    "        return action_values.max(1)[1].item()\n",
    "                            \n",
    "    def decay_exploration(self):\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon_decay * self.epsilon)\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        \n",
    "        return self.get_max_action(state)\n",
    "\n",
    "    def train(self, batch_size=64):\n",
    "        batch_state, batch_action, batch_next_state, batch_reward, batch_done = self.memory.sample(size=batch_size)\n",
    "        Q_next = self.target(batch_next_state).max(1)[0]\n",
    "        Q_actual = batch_reward + (self.gamma * Q_next * (1 - batch_done))\n",
    "        Q_expected = self.model(batch_state).gather(dim=1, index=batch_action.unsqueeze(1)).squeeze(1)\n",
    "        self.model.optimize(Q_expected, Q_actual)\n",
    "        self.update_target()\n",
    "\n",
    "    def remember(self, experience_tuple):\n",
    "        self.memory.add(experience_tuple)\n",
    "\n",
    "    def update_target(self):\n",
    "        for target_param, local_param in zip(self.target.parameters(), self.model.parameters()):\n",
    "            target_param.data.copy_(self.tau * local_param.data + (1.0 - self.tau) * target_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2000 [12:39<79:57:55, 144.30s/it]"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Breakout-v0\")\n",
    "env.seed(0)\n",
    "\n",
    "agent = Agent(env=env)\n",
    "\n",
    "total_episodes = 2000\n",
    "max_steps = 1000\n",
    "batch_size = 32\n",
    "\n",
    "scores = []\n",
    "last_100_scores = deque(maxlen=100)\n",
    "average_rewards = []\n",
    "epsilons = []\n",
    "\n",
    "for episode in tqdm(range(1, total_episodes + 1)):\n",
    "    state = env.reset()\n",
    "    state = state.reshape(3, 210, 160)\n",
    "    score = 0\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        action = agent.get_action(state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        next_state = next_state.reshape(3, 210, 160)\n",
    "        score += reward\n",
    "        agent.remember((state, action, next_state, reward, done))\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        if step % 4 == 0:\n",
    "            if agent.is_ready(batch_size):\n",
    "                agent.train(batch_size=batch_size)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "    last_100_scores.append(score)\n",
    "    scores.append(score)\n",
    "    average_rewards.append(np.mean(last_100_scores))\n",
    "    epsilons.append(agent.epsilon)\n",
    "\n",
    "    agent.decay_exploration()\n",
    "\n",
    "    if episode % 100 == 0:\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode, np.mean(last_100_scores)))\n",
    "    if np.mean(last_100_scores) >= 200:\n",
    "        print(\"Goal Reached\")\n",
    "        torch.save(agent.model.state_dict(), 'checkpoint.pth')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
